"huggingface_ID","parameters (B)","open_llm_average","IFEval","BBH","MATH","GPQA","MUSR","MMLU-Pro"
"Qwen/Qwen2.5-14B-Instruct-1M",14,41.56,84.14,45.66,53.02,12.42,11.35,42.77
"Qwen/Qwen2.5-14B-Instruct",14,41.31,81.58,48.36,54.76,9.62,10.16,43.38
"Qwen/Qwen2.5-7B-Instruct",7,35.20,75.85,34.89,50.00,5.48,8.45,36.52
"Qwen/Qwen2.5-7B-Instruct-1M",7,32.76,74.48,35.03,43.35,6.38,9.52,27.83
"Qwen/Qwen2-7B",7,23.93,31.49,34.71,20.39,7.27,14.32,35.37
"Qwen/Qwen2.5-Math-7B",7,17.84,24.60,22.01,30.51,5.82,5.00,19.09
"Qwen/Qwen2-0.5B",0.5,7.22,18.73,7.92,2.64,1.45,4.60,8.00
"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",14,38.22,43.82,40.69,57.02,18.34,28.71,40.74
"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",7,14.99,40.38,7.88,19.56,3.91,3.55,14.68
"deepseek-ai/DeepSeek-R1-Distill-Llama-8B",8,13.06,37.82,5.33,21.98,0.67,0.46,12.10
"deepseek-ai/deepseek-llm-7b-chat",7,14.82,41.71,11.26,2.04,2.13,19.21,12.59
"deepseek-ai/deepseek-llm-7b-base",7,8.23,21.79,9.77,1.96,3.13,3.76,8.96
"allenai/Llama-3.1-Tulu-3-8B-DPO",8,26.46,80.29,17.43,23.64,5.82,10.52,21.09
"allenai/Llama-3.1-Tulu-3-8B-SFT",8,22.60,74.03,13.93,11.78,3.69,12.01,20.13
"meta-llama/Llama-3.2-3B-Instruct",3,24.20,73.93,24.06,17.67,3.80,1.37,24.39
"meta-llama/Meta-Llama-3-8B-Instruct",8,20.61,47.82,26.80,9.14,5.70,5.40,28.79
"meta-llama/Llama-3.2-3B",3,8.70,13.37,14.23,1.89,2.35,3.81,16.53
"meta-llama/Llama-2-7b-chat-hf",7,9.61,39.86,4.46,1.96,0.45,3.28,7.64
"TinyLlama/TinyLlama_v1.1",1.1,4.82,20.01,3.21,1.21,0.00,3.98,0.54
"TinyLlama/TinyLlama-1.1B-Chat-v0.1",1.1,3.96,14.79,3.36,0.60,0.00,3.90,1.09